# -*- coding:utf-8 -*-
__author__ = 'Qiushi Huang'

# 启动两个线程，py_thread1和py_thread2, 拿到count的初始值，都想对count=0执行一个+1的操作。
# 两个线程都去申请gil_lock，假设py_thread1先申请到了，开始执行解释器代码
# 解释器开始执行py_thread1的python程序，
# 解释器开始调操作系统的原生线程（解释器直接用的是操作系统的原生线程和进程）
# 分配到一个cpu上去执行，假设是cpu1
# 时间过长，操作系统强行释放gil，假设被py_thread2抢到了
# py_thread又重复上面的操作，调解释器、调用原生线程、分配cpu
# 假设分配在了cpu3，且正常执行完成count++
# 释放gil，赋值给count=1
# py_thread1又抢回gil，重复之前第一次执行的所有过程（调解释器、调原生线程、分配cpu、执行计算操作）
# 执行完count++操作，并再一次赋值为count=1
"""
说明gil：保证了线程一个一个执行，但保护的是解释器和垃圾回收的数据，并没有保护Python程序自己的数据。
         针对自己的共享的数据，还要自己加锁。
         
解释器的代码是所有线程共享的，所以垃圾回收线程也可能访问到解释器的代码而去执行，这就导致了一个问题:
对于同一个数据100，可能线程1执行x=100的同时，而垃圾回收执行的是回收100的操作，解决这种问题没有什么高明的方法，就是加锁处理，
如下图的GIL，保证python解释器同一时间只能执行一个任务的代码
"""

"""
总结：
    1、GIL保证的是一个进程内的多个线程同一时间只能有一个执行————这样做事为了保证python的垃圾回收是线程安全的。
    2、针对不同的数据，就应该加不同的锁，解释器级别的GIL锁保护的是解释器级别的数据，针对自己的共享数据，需要自己加锁。
    3、gil不是Python特性，是CPython特性，由于CPython的内存管理垃圾回收机制不是线程安全的因此需要gil这把锁，Python的其他特性都会依赖这把锁。
"""